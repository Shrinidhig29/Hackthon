{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING, FEATURE SELECTION, MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE,SelectKBest\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_selection import f_classif, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-4-e420ddd3308c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-e420ddd3308c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    df_test = pd.read_csv('C:\\Users\\nidhi\\Desktop\\Hackton\\GREYATOM\\Travel_Insurance\\Data\\train.csv')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Loading the Data\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\nidhi\\\\Desktop\\Hackton\\GREYATOM\\Travel_Insurance\\Data\\train.csv')\n",
    "df_train = pd.read_csv('C:\\Users\\nidhi\\Desktop\\Hackton\\GREYATOM\\Travel_Insurance\\Data\\train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot before outlier treatment\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.boxplot(y=df_train[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.boxplot(y=df_train[\"Duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duration: Min = -2 Max = 4881 But can insurance company giving insurance for 4881 days? <br>\n",
    "Insurance company do not give insurance over 360 days. Further extension will be provided for 180 days.\n",
    "we are considering 540 days as a limit.\n",
    "\n",
    "- Age. Min = 0 Max = 118 age 0 can be possible but 118 too old however we need to check too old people gets insurance or not. So,Insurance Companies do not give insurance over an age of 85.However there are few who provide insurance upto age of 99. so we treat the values above 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['Duration'] > 540 ].shape\n",
    "df_train[df_train['Age'] > 99 ].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for data preprocessing\n",
    "def age_convert(age):\n",
    "    result = ''\n",
    "    if(age <= 21):\n",
    "        result = 'Child'\n",
    "    elif(age <= 50):\n",
    "        result = 'Adult'\n",
    "    else:\n",
    "        result = 'Senior'\n",
    "    return result\n",
    "\n",
    "\n",
    "def pre_processing(train_data):\n",
    "    train_data['Age Group'] = train_data['Age'].map(lambda x: age_convert(x))\n",
    "    train_data['Duration'][train_data['Duration'] < 0] = train_data['Duration'].median()\n",
    "    train_data['Duration'][train_data['Duration'] > 540] = 540\n",
    "    train_data['Age'][train_data['Age'] > 99] = train_data[train_data['Age Group'] == 'Senior']['Age'].mean()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot after outlier treatment\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.boxplot(y = df_train[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.boxplot(y = df_train[\"Duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Columns to drop \n",
    "cat_col = ['Agency', 'Agency Type', 'Distribution Channel', 'Product Name', 'Destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df_train[cat_col]\n",
    "X_cat.head(2)\n",
    "X_cat_one_hot_train = pd.get_dummies(X_cat, drop_first=True)\n",
    "\n",
    "#Merge With original df\n",
    "cat_proc_columns = X_cat_one_hot_train.columns\n",
    "for col in cat_proc_columns:\n",
    "    df_train[col] = X_cat_one_hot_train[col] \n",
    "    \n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df_test[cat_col]\n",
    "X_cat_one_hot = pd.get_dummies(X_cat, drop_first=True)\n",
    "\n",
    "#Merge With original df\n",
    "cat_proc_columns = X_cat_one_hot.columns\n",
    "for col in cat_proc_columns:\n",
    "    df_test[col] = X_cat_one_hot[col] \n",
    "    \n",
    "df_test.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns = cat_col)\n",
    "df_train = df_train.drop(columns = cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['ID'])\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['ID'])\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Numerical Data [Co-relation ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "updated_data = df_train\n",
    "updated_data_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# checking crelation in numerical column\n",
    "#num_df=updated_data.select_dtypes(include=['number']).copy()\n",
    "df_num = df_train[['Duration', 'Age', 'Net Sales', 'Commision (in value)', 'Claim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ploting heatmap to check corelation in numerical feature in data.\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_num.corr(), annot=True)\n",
    "plt.title('Heatmap for detecting multicollinearity', fontsize=16, color='navy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Highest Co related features are Net Sales vs Commission. Further Process or drop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Numerical Input, Categorical Output ==> ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_num = df_train[['Duration', 'Age', 'Net Sales', 'Commision (in value)', 'Claim']]\n",
    "df_num = df_num[df_num.Duration > 0]\n",
    "X = df_num.iloc[:,:-1]\n",
    "y = df_num.iloc[:,-1]\n",
    "\n",
    "# Apply Anova and fit the logistic model on train data use df dataset\n",
    "nof_list   = [1, 2, 3, 4]\n",
    "high_score = 0\n",
    "nof        = 0\n",
    "\n",
    "for n in nof_list:\n",
    "    test = SelectKBest(score_func = f_classif , k = n)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "    X_train = test.fit_transform(X_train,y_train)\n",
    "    X_test = test.transform(X_test)\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"For no of features=\",n,\", score=\", model.score(X_test,y_test))\n",
    "    \n",
    "    if model.score(X_test,y_test) > high_score:\n",
    "        high_score = model.score(X_test, y_test)\n",
    "        model_ = model\n",
    "        nof=n \n",
    "    print(\"High Score is:\",high_score, \"with features=\", nof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- High Score is for 1. Not changing much can go ahead with 4 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feat_importances.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = updated_data['Claim']\n",
    "X = updated_data.drop(columns=['Claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(columns='Age Group')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Balanced Dataset [SMOTE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=7)\n",
    "X_SMOTE, y_SMOTE = smote.fit_resample(X, y)\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_SMOTE, y_SMOTE, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Balanced Dataset [SMOTE Tomek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tomek = SMOTETomek(random_state=42)\n",
    "X_SMOTE_TK, y_SMOTE_TK = smote.fit_resample(X, y)\n",
    "X_train_smotetk, X_test_smotetk, y_train_smotetk, y_test_smotetk = train_test_split(X_SMOTE_TK, y_SMOTE_TK, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = {'random_forest':RandomForestClassifier(min_samples_split= 2, min_samples_leaf= 1,\\\n",
    "    max_features= 'sqrt', max_depth= 560,criterion= 'entropy'), \n",
    "          'logistic_reg':LogisticRegression(), \n",
    "          'XGB':XGBClassifier(), \n",
    "          'DT': DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_model(models, X_train, y_train):\n",
    "    for name, model in models.items():\n",
    "        score = cross_val_score(model, X_train, y_train, cv=StratifiedKFold(shuffle=True),\\\n",
    "                                scoring='recall', n_jobs=-1)\n",
    "        print(f'{name} Precision score : {np.mean(score)}')\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(updated_data_test1)\n",
    "        y_pred1 = model.predict(X_test)\n",
    "        print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred1))\n",
    "        print(\"==\"*20)\n",
    "        print(\"Classification Report: \\n\",classification_report(y_test,y_pred1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df_train['Claim']\n",
    "X = df_train.drop(columns=['Claim'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# Build a forest and compute the feature importances\n",
    "rff = RandomForestClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=5,\n",
    "                       n_estimators=50, random_state=9)\n",
    "\n",
    "rff.fit(X, y)\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(forest.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).sort_values(ascending=True).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df_train['Claim']\n",
    "X = df_train.drop(columns=['Claim'])\n",
    "\n",
    "column_names = ['Duration', 'Net Sales', 'Age', 'Commision (in value)', 'Agency_C2B', 'Destination_SINGAPORE', \\\n",
    "               'Agency Type_Travel Agency']\n",
    "X = X[column_names]\n",
    "updated_data_test = updated_data_test[column_names]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.3)\n",
    "scaler = StandardScaler()\n",
    "#scaler  = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "# Build a forest and compute the feature importances\n",
    "rff = RandomForestClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=5,\n",
    "                       n_estimators=50, random_state=9)\n",
    "\n",
    "rff.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred1 = rff.predict(X_test)\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred1))\n",
    "print(\"==\"*20)\n",
    "print(\"Classification Report: \\n\",classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./file/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ID = df_test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rff.predict(df_test)\n",
    "len(list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
